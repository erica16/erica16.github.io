---
title: "Quarto Basics"
format:
  html:
    code-fold: true
jupyter: python3
editor:
  render-on-save: true
---
# Anomaly/Outlier Detection on the correlation between CO2 Emissions and Economic Inequality metric by country
As someone who majored in Environmental Informatics for my undergrad at Virginia Tech, exploring climate data and its relationship to non-climate datasets is something that I am familiar with and very passionate about. I wanted to make sure I had a set of data to use for a study on anomaly and outlier detection that would show a strong correlation between the two variables, but maybe not one that would come straight to mind for the average person. I had a hunch that the Inequality index for a country and the CO2 emissions for a country might be correlated, so I found a C02 emissions dataset from <https://www.kaggle.com/datasets/ankanhore545/carbon-dioxide-emissions-of-the-world> and an Economic Inequality dataset from <https://ourworldindata.org/economic-inequality>.

## What are these variables?
**C02**, or carbon dioxide, is one of the primary greenhouse gases responsible for driving climate change. As a greenhouse gas, its presence traps infrared radiation (heat) in the atmosphere which keeps earth comfortable in natural amounts but is detrimental when the amounts are much higher than they would normally be due to human-caused spikes in CO2 emissions. Massive increases in carbon dioxide emissions are primarily due to burning fossil fuels and other biomass-based fuels for energy used in industrial, housing, and transportation settings, and large changes in land use patterns.
**Income Inequality** per country is measured with the **Gini Coefficient**, which is a measure of the income inequality from 0 to 1 where 0 is perfect income equality and 1 is the maximal inequality. It helps assess how evenly or unevenly the wealth in a population is distributed. It is calculated by measuring a value like income on a frequency distribution, where a 45 degree angle would indicate perfect wealth distribution.

## Step 1: Clean data and view the basic scatterplot
The first thing to do after downloading the datasets and hosting them on my git repo was to explore the data, and the best way to do that is to get it onto a visualization. Before being able to visualize it though, the data needs to be cleaned - in this case, that means removing rows without useable data and making the dataframes easier to use by filtering out unnecessary columns. After the data is presentable in two separate dataframes, it needs to be merged into the same dataframe so that it can be graphed. I merged the CO2 Emissions dataframe and the Income Inequality index dataframe on Country after filtering for just rows in the Inequality dataframe where the year was 2018. I chose 2018 because it was the most recent year with data in both datasets.

```{python}
import matplotlib.pyplot as plt
import numpy as np
import pandas as pd
import seaborn as sns
from sklearn.linear_model import LinearRegression
from sklearn.model_selection import train_test_split
from sklearn.impute import SimpleImputer
from sklearn.metrics import r2_score
from sklearn.preprocessing import StandardScaler


emissions_csv = 'https://raw.githubusercontent.com/erica16/ml1_blogs/main/data/historical_emissions.csv'
inequality_csv ='https://raw.githubusercontent.com/erica16/ml1_blogs/main/data/inequality.csv'

#read in datasets
emissions_df = pd.read_csv(emissions_csv)
inequality_df = pd.read_csv(inequality_csv)

#clean data
inequality_filtered = inequality_df.filter(['Country', 'Year', 'Gini coefficient (before tax) (World Inequality Database)'])

print(emissions_df.info())

#filter to 2018
inequality_2018 = inequality_filtered.loc[inequality_filtered['Year'] == 2018]
print(inequality_2018.info())

#merge dfs on country
inequality_emissions_df = inequality_2018.merge(emissions_df, on='Country')
in_em_nums = inequality_emissions_df.select_dtypes(include=[np.number])
imputer = SimpleImputer(strategy="median")
imputer.fit(in_em_nums)
in_em_imputed = imputer.transform(in_em_nums)
inequality_emissions_df[in_em_nums.columns] = in_em_imputed


# Visualize the data
sns.scatterplot(data=inequality_emissions_df, x='Gini coefficient (before tax) (World Inequality Database)' ,y='2018')
plt.xlabel('Inequality index (Gini Coefficient, before tax)')
plt.ylabel('CO2 Emissions in MtCO₂e')
plt.title('Correlation between CO2 Emissions and Inequality metric by Country in 2018')
plt.show()
```

## Step 2: Evaluate scatterplot findings
Looking at this scatterplot, 2 things are immediately obvious: the first is that almost all the points are clustered towards the bottom of the Y axis, but are clustered nonetheless, and the second is that there is one visually obvious outlier and one point that could be an outlier but requires further investigation. 

## Step 3: K-means clustering to determine outliers
In order to decide which of these points are truly outliers, I will use a K-means cluster with only 2 clusters, and the outcome will show the majority of the dataset in one cluster and the outliers in the other cluster.

```{python}
# k-means clusterer
ineq_emiss_np = np.array(inequality_emissions_df[['Gini coefficient (before tax) (World Inequality Database)', '2018']])

k = 2
kmeans = KMeans(n_clusters=k, random_state=42)
y_pred = kmeans.fit_predict(ineq_emiss_np)

# plot decision boundaries
mins = ineq_emiss_np.min(axis=0) - 0.1
maxs = ineq_emiss_np.max(axis=0) + 0.1
xx, yy = np.meshgrid(np.linspace(mins[0], maxs[0], 1000),
                      np.linspace(mins[1], maxs[1], 1000))
Z = kmeans.predict(np.c_[xx.ravel(), yy.ravel()])
Z = Z.reshape(xx.shape)

plt.contourf(Z, extent=(mins[0], maxs[0], mins[1], maxs[1]),
            cmap='Set3')
plt.contour(Z, extent=(mins[0], maxs[0], mins[1], maxs[1]),
            linewidths=1, colors='k')

# plot data
sns.scatterplot(data=inequality_emissions_df, x='Gini coefficient (before tax) (World Inequality Database)', y='2018', s = 100)

plt.xlabel('Inequality index (Gini Coefficient, before tax)')
plt.ylabel('CO2 Emissions in MtCO₂e')
plt.title('Correlation between CO2 Emissions and Inequality metric by Country in 2018')
plt.show()
```

Based on this graph, the yellow cluster at the top holds the single outlier for the dataset, while the bottom turquoise cluster holds the valid data for the dataset, including the two points we weren't totally sure were going to be part of the valid dataset. This goes to show that a machine learning algorithm is a great way to determine what points are outliers, especially when it is dubious upon visual inspection. If we want to be a little bit more discerning with the outlier detection, we could try for 3 clusters.

```{python}
# k-means clusterer
ineq_emiss_np = np.array(inequality_emissions_df[['Gini coefficient (before tax) (World Inequality Database)', '2018']])

k = 3
kmeans = KMeans(n_clusters=k, random_state=42)
y_pred = kmeans.fit_predict(ineq_emiss_np)

# plot decision boundaries
mins = ineq_emiss_np.min(axis=0) - 0.1
maxs = ineq_emiss_np.max(axis=0) + 0.1
xx, yy = np.meshgrid(np.linspace(mins[0], maxs[0], 1000),
                      np.linspace(mins[1], maxs[1], 1000))
Z = kmeans.predict(np.c_[xx.ravel(), yy.ravel()])
Z = Z.reshape(xx.shape)

plt.contourf(Z, extent=(mins[0], maxs[0], mins[1], maxs[1]),
            cmap='Set3')
plt.contour(Z, extent=(mins[0], maxs[0], mins[1], maxs[1]),
            linewidths=1, colors='k')

# plot data
sns.scatterplot(data=inequality_emissions_df, x='Gini coefficient (before tax) (World Inequality Database)', y='2018', s = 100)

plt.xlabel('Inequality index (Gini Coefficient, before tax)')
plt.ylabel('CO2 Emissions in MtCO₂e')
plt.title('Correlation between CO2 Emissions and Inequality metric by Country in 2018')
plt.show()
```

Here we can see that the outlier from the two cluster graph is still in its own cluster, but the point second-furthest away from the majority of the group is now in its own cluster, and the point third-furthest away seems to be straddling the line between possible outlier and valid data point. The cluster containing the majority of the points is the one containing the valid data.