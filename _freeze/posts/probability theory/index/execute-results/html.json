{
  "hash": "cc94ae569d00d332fe865754e640d13f",
  "result": {
    "markdown": "---\ntitle: Probability Theory and Random Variables\nformat:\n  html:\n    code-fold: true\neditor:\n  render-on-save: true\n---\n\nBayes' rule, or Bayes' theorem or Bayes' law, describes the probability of an event occurring given prior knowledge of conditions that could be related to said event.\n\nI am interested in exploring the relationship between a country's happiness score and how much renewable energy the country uses. \nHappiness scores have been measured for citizens of countries using the World Happiness Report, which is gathered from the Gallup World Poll. The happiness score is also known as the Cantril score because the main question asked to determine a citizens happiness is:\n“Please imagine a ladder, with steps numbered from 0 at the bottom to 10 at the top. The top of the ladder represents the best possible life for you and the bottom of the ladder represents the worst possible life for you. On which step of the ladder would you say you personally feel you stand at this time?”\nAnd the ladder in reference is also called the Cantril ladder.\n\nMy data resources are https://ourworldindata.org/renewable-energy for renewable energy and https://ourworldindata.org/happiness-and-life-satisfaction for happiness. \n\nFirst, import all libraries and pull data from github into pandas dataframes.\n\n::: {.cell execution_count=1}\n``` {.python .cell-code}\nimport matplotlib.pyplot as plt\nimport numpy as np\nimport pandas as pd\nimport seaborn as sns\nfrom sklearn.linear_model import LinearRegression\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import r2_score\nfrom sklearn.naive_bayes import GaussianNB\nfrom sklearn.metrics import accuracy_score\n\nhappy_csv = 'https://raw.githubusercontent.com/erica16/ml1_blogs/main/data/happiness-cantril-ladder.csv'\nrenew_csv = 'https://raw.githubusercontent.com/erica16/ml1_blogs/main/data/renewable-share-energy.csv'\npercent_renew_csv = 'https://raw.githubusercontent.com/erica16/ml1_blogs/main/data/modern-renewable-energy-consumption.csv'\n\n# read in datasets\nhappy_df = pd.read_csv(happy_csv)\nrenew_df = pd.read_csv(renew_csv)\npercent_renew_df = pd.read_csv(percent_renew_csv)\n```\n:::\n\n\nFor this task, I have 3 datasets - one for the happiness metric, one for the percentage of country's energy that comes from renewable sources, and one for the breakdown of a country's renewable energy sources in TWh (terawatt hours).\nSince the amount of energy a country consumes varies per country, we need to have a way of being able to compare the renewable energy source breakdowns reliably between countries. For this, I made a function that takes all the renewable sources and turns each value into a percentage.\n\n::: {.cell execution_count=2}\n``` {.python .cell-code}\n# takes row in the renewable energy consumption breakdown datatable and turns each data column\n# into a percent value rounded to the nearest 100ths decimal place.\ndef calculate_percentages(row):\n    other = row[3]\n    solar = row[4]\n    wind = row[5]\n    hydro = row[6]\n    total = other + wind + solar + hydro\n    if (total == 0):\n        return pd.Series([0, 0, 0, 0])\n    else:\n        return pd.Series(\n            [(other/total) * 100, \n            (solar/total) * 100, \n            (wind/total) * 100, \n            (hydro/total) * 100\n            ])\n```\n:::\n\n\nNow that we have a good way of comparing all the data on the same scale, we can get our dataframes ready to merge and then analyze. \nFirst we can narrow down the dataframes to just the columns we need, and filter the data to just years 2011 and after because the happiness index dataset starts at 2011.\n\n::: {.cell execution_count=3}\n``` {.python .cell-code}\n# clean data\npercent_renew_df[['Other', 'Solar', 'Wind', 'Hydro']] = percent_renew_df.apply(calculate_percentages, axis=1)\npercent_renew_clean = percent_renew_df.filter(['Entity', 'Year', 'Other', 'Solar', 'Wind', 'Hydro'])\npercent_renew_clean['Largest Renewable Source'] = percent_renew_clean[['Other', 'Solar', 'Wind', 'Hydro']].idxmax(axis=1)\nhappy_df_rename = happy_df.rename(columns={'Cantril ladder score':'Happiness Score'})\nrenew_df_rename = renew_df.rename(columns={renew_df.columns[3]:'Percent Renewable Energy'})\n\n# filter to after 2010 because the happiness dataset starts at 2011\nhappy_years = happy_df_rename.loc[happy_df_rename['Year'] > 2010]\nrenew_years = renew_df_rename.loc[renew_df_rename['Year']> 2010]\npercent_renew_years = percent_renew_clean.loc[percent_renew_clean['Year'] > 2010]\n\n# merge dfs on country\nhappy_renew_df = happy_years.merge(renew_years, on='Entity')\n\nall_df = happy_renew_df.merge(percent_renew_years, on='Entity')\n\nall_xy = all_df.filter(['Happiness Score', 'Percent Renewable Energy', 'Solar', 'Wind', 'Hydro', 'Other', 'Largest Renewable Source']).dropna()\n\nprint(all_xy.info())\nsns.scatterplot(data=all_xy, x='Percent Renewable Energy', y='Happiness Score', s=12, hue='Largest Renewable Source')\nplt.title(\"Country Happiness Score vs Percent Renewable Energy\")\nplt.show()\n```\n\n::: {.cell-output .cell-output-stderr}\n```\nC:\\Users\\Erica\\AppData\\Local\\Temp\\ipykernel_74056\\3612890870.py:4: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n  other = row[3]\nC:\\Users\\Erica\\AppData\\Local\\Temp\\ipykernel_74056\\3612890870.py:5: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n  solar = row[4]\nC:\\Users\\Erica\\AppData\\Local\\Temp\\ipykernel_74056\\3612890870.py:6: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n  wind = row[5]\nC:\\Users\\Erica\\AppData\\Local\\Temp\\ipykernel_74056\\3612890870.py:7: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n  hydro = row[6]\nC:\\Users\\Erica\\AppData\\Local\\Temp\\ipykernel_74056\\1829548257.py:4: FutureWarning: The behavior of DataFrame.idxmax with all-NA values, or any-NA and skipna=False, is deprecated. In a future version this will raise ValueError\n  percent_renew_clean['Largest Renewable Source'] = percent_renew_clean[['Other', 'Solar', 'Wind', 'Hydro']].idxmax(axis=1)\n```\n:::\n\n::: {.cell-output .cell-output-stdout}\n```\n<class 'pandas.core.frame.DataFrame'>\nIndex: 97440 entries, 0 to 97559\nData columns (total 7 columns):\n #   Column                    Non-Null Count  Dtype  \n---  ------                    --------------  -----  \n 0   Happiness Score           97440 non-null  float64\n 1   Percent Renewable Energy  97440 non-null  float64\n 2   Solar                     97440 non-null  float64\n 3   Wind                      97440 non-null  float64\n 4   Hydro                     97440 non-null  float64\n 5   Other                     97440 non-null  float64\n 6   Largest Renewable Source  97440 non-null  object \ndtypes: float64(6), object(1)\nmemory usage: 5.9+ MB\nNone\n```\n:::\n\n::: {.cell-output .cell-output-display}\n![](index_files/figure-html/cell-4-output-3.png){width=576 height=449}\n:::\n:::\n\n\nHere is our first look at the dataset. From the scatterplot, we can see that there is clearly not a tight relationship between the variables, but it does seem to be generally a positive trend.\n\nNow we can run some models on the data and try to see a relationship, starting with a linear regression. Before running the linear regression, my guess is what I stated in the previous paragraph - there will be a loose positive trend.\n\n::: {.cell execution_count=4}\n``` {.python .cell-code}\nX = all_xy['Percent Renewable Energy']\ny = all_xy['Happiness Score']\n\n# linear regression\ntrain_set_X, test_set_X, train_set_y, test_set_y= train_test_split(np.array(X).reshape(-1, 1), np.array(y), test_size=0.2, random_state=42)\n\nlin_reg = LinearRegression()\nlin_reg.fit(train_set_X, train_set_y)\nlin_reg.intercept_, lin_reg.coef_\ny_pred = lin_reg.predict(test_set_X)\n\nsns.scatterplot(data=all_xy, x='Percent Renewable Energy', y='Happiness Score', s=12, hue='Largest Renewable Source')\nplt.plot(test_set_X, y_pred, color='red')\nplt.title(\"Country Happiness Score vs Percent Renewable Energy\")\nplt.show()\nprint(\"r-squared = {:.3f}\".format(r2_score(X, y)))\n```\n\n::: {.cell-output .cell-output-display}\n![](index_files/figure-html/cell-5-output-1.png){width=576 height=449}\n:::\n\n::: {.cell-output .cell-output-stdout}\n```\nr-squared = -0.334\n```\n:::\n:::\n\n\nNow that we can see the positive trendline, we know my guess was right. That r-squared value is pretty unfortunate though. A negative r-squared value means the model performs very poorly for this dataset, so it may be useful to check out a different type of model.\n\nInstead of doing a Linear Regression, I am doing a Gaussian Naive Bayes model. This is a model that assumes that the numerical attributes like Happiness Score are distributed normally, and assumes independence among the features in order to apply Bayes' theorem.\n\nSince it needs to compare a categorical variable with a continuous numerical variable, I am going to be using the Happiness Score to predict a country's Largest Renewable Resource.\n\n::: {.cell execution_count=5}\n``` {.python .cell-code}\nX = all_xy['Happiness Score']\ny = all_xy['Largest Renewable Source']\ntrain_set_X, test_set_X, train_set_y, test_set_y= train_test_split(np.array(X).reshape(-1, 1), np.array(y), test_size=0.2, random_state=42)\n\ngnb = GaussianNB()\nprint(train_set_X)\nprint(train_set_y)\ngnb.fit(train_set_X, train_set_y)\ngnb_predict = gnb.predict(test_set_X)\n\nprint(accuracy_score(test_set_y, gnb_predict))\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[[6.3338  ]\n [5.234   ]\n [5.089082]\n ...\n [4.8141  ]\n [5.2946  ]\n [6.1718  ]]\n['Hydro' 'Hydro' 'Hydro' ... 'Wind' 'Solar' 'Hydro']\n0.6616892446633826\n```\n:::\n:::\n\n\nThe Gaussian Naive Bayes model is 66% accurate! This means that 66 times out of 100, the model will correctly predict a country's largest renewable source given the country's happiness score.\n\n",
    "supporting": [
      "index_files"
    ],
    "filters": [],
    "includes": {}
  }
}